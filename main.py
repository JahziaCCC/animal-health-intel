import os
import re
import json
import hashlib
import datetime
import requests
import xml.etree.ElementTree as ET

BOT = os.environ["TELEGRAM_BOT_TOKEN"]
CHAT_ID = os.environ["TELEGRAM_CHAT_ID"]

KSA_TZ = datetime.timezone(datetime.timedelta(hours=3))
STATE_FILE = "state.json"

# ===== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª =====
MAX_ITEMS = 8
MAX_AGE_DAYS = 120  # Ø®Ù„ÙŠÙ‡Ø§ 90-180 Ø­Ø³Ø¨ Ø±ØºØ¨ØªÙƒ

# Ø¯ÙˆÙ„ ØªØ­Øª Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© (ØªÙ‚Ø¯Ø± ØªØ²ÙŠØ¯)
COUNTRY_KEYS = {
    "saudi arabia": "Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©",
    "kingdom of saudi arabia": "Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©",
    "ksa": "Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©",
    "sudan": "Ø§Ù„Ø³ÙˆØ¯Ø§Ù†",
    "somalia": "Ø§Ù„ØµÙˆÙ…Ø§Ù„",
    "ethiopia": "Ø¥Ø«ÙŠÙˆØ¨ÙŠØ§",
    "djibouti": "Ø¬ÙŠØ¨ÙˆØªÙŠ",
    "jordan": "Ø§Ù„Ø£Ø±Ø¯Ù†",
    "india": "Ø§Ù„Ù‡Ù†Ø¯",
    "pakistan": "Ø¨Ø§ÙƒØ³ØªØ§Ù†",
    "australia": "Ø£Ø³ØªØ±Ø§Ù„ÙŠØ§",
    "brazil": "Ø§Ù„Ø¨Ø±Ø§Ø²ÙŠÙ„",
}

# Ø£Ù…Ø±Ø§Ø¶Ùƒ (Ø£Ø³Ù…Ø§Ø¡ ÙƒØ§Ù…Ù„Ø© + Ø§Ø®ØªØµØ§Ø± Ø¨Ø´Ø±Ø· Ø³ÙŠØ§Ù‚)
DISEASE_FULL = {
    "rift valley fever": "Ø­Ù…Ù‘Ù‰ Ø§Ù„ÙˆØ§Ø¯ÙŠ Ø§Ù„Ù…ØªØµØ¯Ù‘Ø¹ (RVF)",
    "peste des petits ruminants": "Ø·Ø§Ø¹ÙˆÙ† Ø§Ù„Ù…Ø¬ØªØ±Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© (PPR)",
    "foot and mouth disease": "Ø§Ù„Ø­Ù…Ù‘Ù‰ Ø§Ù„Ù‚Ù„Ø§Ø¹ÙŠØ© (FMD)",
    "avian influenza": "Ø¥Ù†ÙÙ„ÙˆÙ†Ø²Ø§ Ø§Ù„Ø·ÙŠÙˆØ±",
    "highly pathogenic avian influenza": "Ø¥Ù†ÙÙ„ÙˆÙ†Ø²Ø§ Ø§Ù„Ø·ÙŠÙˆØ± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¥Ù…Ø±Ø§Ø¶ (HPAI)",
    "lumpy skin disease": "Ù…Ø±Ø¶ Ø§Ù„Ø¬Ù„Ø¯ Ø§Ù„Ø¹Ù‚Ø¯ÙŠ (LSD)",
    "anthrax": "Ø§Ù„Ø¬Ù…Ø±Ø© Ø§Ù„Ø®Ø¨ÙŠØ«Ø©",
    "rabies": "Ø¯Ø§Ø¡ Ø§Ù„ÙƒÙ„Ø¨",
}

DISEASE_ABBR = {
    "rvf": "Ø­Ù…Ù‘Ù‰ Ø§Ù„ÙˆØ§Ø¯ÙŠ Ø§Ù„Ù…ØªØµØ¯Ù‘Ø¹ (RVF)",
    "ppr": "Ø·Ø§Ø¹ÙˆÙ† Ø§Ù„Ù…Ø¬ØªØ±Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© (PPR)",
    "fmd": "Ø§Ù„Ø­Ù…Ù‘Ù‰ Ø§Ù„Ù‚Ù„Ø§Ø¹ÙŠØ© (FMD)",
    "h5n1": "Ø¥Ù†ÙÙ„ÙˆÙ†Ø²Ø§ Ø§Ù„Ø·ÙŠÙˆØ± (H5N1)",
}

DISEASE_CONTEXT = [
    "outbreak", "case", "cases", "fever", "virus", "infection",
    "detected", "confirmed", "epidemic", "surveillance", "vaccination",
]

REGION_AR = {
    "riyadh": "Ø§Ù„Ø±ÙŠØ§Ø¶",
    "makkah": "Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø©",
    "madinah": "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ù†ÙˆØ±Ø©",
    "eastern province": "Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ©",
    "qassim": "Ø§Ù„Ù‚ØµÙŠÙ…",
    "asir": "Ø¹Ø³ÙŠØ±",
    "tabuk": "ØªØ¨ÙˆÙƒ",
    "hail": "Ø­Ø§Ø¦Ù„",
    "jazan": "Ø¬Ø§Ø²Ø§Ù†",
    "najran": "Ù†Ø¬Ø±Ø§Ù†",
    "al bahah": "Ø§Ù„Ø¨Ø§Ø­Ø©",
    "al jawf": "Ø§Ù„Ø¬ÙˆÙ",
    "northern borders": "Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø´Ù…Ø§Ù„ÙŠØ©",
    "khartoum": "Ø§Ù„Ø®Ø±Ø·ÙˆÙ…",
    "darfur": "Ø¯Ø§Ø±ÙÙˆØ±",
    "oromia": "Ø£ÙˆØ±ÙˆÙ…ÙŠØ§",
    "amhara": "Ø£Ù…Ù‡Ø±Ø§",
    "addis ababa": "Ø£Ø¯ÙŠØ³ Ø£Ø¨Ø§Ø¨Ø§",
    "amman": "Ø¹Ù…Ù‘Ø§Ù†",
    "irbid": "Ø¥Ø±Ø¨Ø¯",
}

# Ù…ØµØ§Ø¯Ø±
PROMED_RSS = "https://promedmail.org/promed-posts?format=rss"
GOOGLE_RSS = "https://news.google.com/rss/search?q={q}&hl=en&gl=US&ceid=US:en"
GDELT_DOC = "https://api.gdeltproject.org/api/v2/doc/doc"


# ===== ÙˆÙ‚Øª =====
def now_ksa():
    return datetime.datetime.now(tz=KSA_TZ)

def now_ksa_str():
    return now_ksa().strftime("%Y-%m-%d %H:%M") + " Ø¨ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©"


# ===== Telegram =====
def tg_send(text: str):
    url = f"https://api.telegram.org/bot{BOT}/sendMessage"
    parts = [text[i:i+3500] for i in range(0, len(text), 3500)]
    for p in parts:
        r = requests.post(
            url,
            json={"chat_id": CHAT_ID, "text": p, "disable_web_page_preview": True},
            timeout=30
        )
        r.raise_for_status()


# ===== State =====
def load_state():
    try:
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return {"seen": {}}

def save_state(state):
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

def make_sid(url, title):
    raw = (url or "") + "|" + (title or "")
    return hashlib.sha256(raw.encode()).hexdigest()[:16]


# ===== ÙƒØ´Ù =====
def detect_country(text):
    low = (text or "").lower()
    for k, v in COUNTRY_KEYS.items():
        if k in low:
            return v
    return None

def detect_region(text, country_ar):
    low = (text or "").lower()
    for k, v in REGION_AR.items():
        if k in low:
            return v
    return "Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¯ÙˆÙ„Ø©" if country_ar else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

def detect_disease(text):
    low = (text or "").lower()

    # 1) Ø£Ø³Ù…Ø§Ø¡ ÙƒØ§Ù…Ù„Ø©
    for k, v in DISEASE_FULL.items():
        if k in low:
            return v

    # 2) Ø§Ø®ØªØµØ§Ø± Ø¨Ø´Ø±Ø· Ø³ÙŠØ§Ù‚
    has_context = any(c in low for c in DISEASE_CONTEXT)
    if has_context:
        for k, v in DISEASE_ABBR.items():
            if re.search(rf"\b{k}\b", low):
                return v

    return None

def classify_item(title: str, desc: str) -> str:
    low = f"{title} {desc}".lower()
    if "outbreak" in low or "confirmed" in low or "cases" in low:
        return "ğŸŸ¥ ØªÙØ´ÙŠ/Ø­Ø§Ù„Ø§Øª"
    if "ban" in low or "imports" in low or "import ban" in low:
        return "ğŸŸ¦ Ù‚Ø±Ø§Ø±/Ù…Ù†Ø¹ Ø§Ø³ØªÙŠØ±Ø§Ø¯"
    if "study" in low or "investigation" in low or "characterization" in low:
        return "ğŸŸ© Ø¯Ø±Ø§Ø³Ø©/Ø¨Ø­Ø«"
    return "ğŸŸ¨ Ø®Ø¨Ø± Ø¹Ø§Ù…"


# ===== ÙÙ„ØªØ±Ø© Ø§Ù„Ø¹Ù…Ø± (Ù„Ù€ GDELT/Google) =====
def within_days(iso_or_pubdate: str, days: int) -> bool:
    if not iso_or_pubdate:
        return True
    # GDELT ISO: 2026-02-28T00:00:00Z
    try:
        if "T" in iso_or_pubdate and iso_or_pubdate.endswith("Z"):
            dt = datetime.datetime.strptime(iso_or_pubdate, "%Y-%m-%dT%H:%M:%SZ")
            dt = dt.replace(tzinfo=datetime.timezone.utc)
        else:
            # Google pubDate: Sat, 28 Feb 2026 00:00:00 GMT
            dt = datetime.datetime.strptime(iso_or_pubdate, "%a, %d %b %Y %H:%M:%S %Z")
            dt = dt.replace(tzinfo=datetime.timezone.utc)

        age = now_ksa() - dt.astimezone(KSA_TZ)
        return age.days <= days
    except:
        return True


# ===== Ø¬Ù„Ø¨ ProMED RSS =====
def fetch_promed():
    headers = {"User-Agent": "Mozilla/5.0"}
    r = requests.get(PROMED_RSS, timeout=45, headers=headers)
    r.raise_for_status()
    root = ET.fromstring(r.text)

    items = []
    for it in root.findall(".//item"):
        items.append({
            "source": "ProMED",
            "title": (it.findtext("title") or "").strip(),
            "link": (it.findtext("link") or "").strip(),
            "pub": (it.findtext("pubDate") or "").strip(),
            "desc": (it.findtext("description") or "").strip(),
        })
    return items


# ===== Ø¬Ù„Ø¨ Google News RSS =====
def fetch_google(query):
    url = GOOGLE_RSS.format(q=requests.utils.quote(query))
    headers = {"User-Agent": "Mozilla/5.0"}
    r = requests.get(url, timeout=45, headers=headers)
    r.raise_for_status()
    root = ET.fromstring(r.text)

    items = []
    for it in root.findall(".//item"):
        items.append({
            "source": "Google News",
            "title": (it.findtext("title") or "").strip(),
            "link": (it.findtext("link") or "").strip(),
            "pub": (it.findtext("pubDate") or "").strip(),
            "desc": (it.findtext("description") or "").strip(),
        })
    return items


# ===== Ø¬Ù„Ø¨ GDELT =====
def fetch_gdelt(query, maxrecords=50):
    params = {
        "query": query,
        "mode": "ArtList",
        "format": "json",
        "sort": "HybridRel",
        "maxrecords": str(maxrecords),
        "formatting": "json",
    }
    headers = {"User-Agent": "Mozilla/5.0"}
    r = requests.get(GDELT_DOC, params=params, timeout=45, headers=headers)
    r.raise_for_status()
    data = r.json()

    items = []
    for a in data.get("articles", []) or []:
        items.append({
            "source": "GDELT",
            "title": (a.get("title") or "").strip(),
            "link": (a.get("url") or "").strip(),
            "pub": (a.get("seendate") or "").strip(),  # ISO Z
            "desc": (a.get("sourceCountry") or "") + " " + (a.get("snippet") or ""),
        })
    return items


def main():
    state = load_state()

    # Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙˆØ§Ø³Ø¹ Ù„ÙƒÙ† â€œØ°ÙƒÙŠâ€ Ø¯Ø§Ø®Ù„ Ø§Ù„ÙƒÙˆØ¯ Ù‡Ùˆ Ø§Ù„Ù„ÙŠ ÙŠÙÙ„ØªØ±
    countries_q = "(Saudi Arabia OR Sudan OR Somalia OR Ethiopia OR Djibouti OR Jordan OR India)"
    diseases_q = '("rift valley fever" OR RVF OR "peste des petits ruminants" OR PPR OR "foot and mouth disease" OR FMD OR "avian influenza" OR H5N1 OR "lumpy skin disease")'
    context_q = "(outbreak OR cases OR virus OR fever OR confirmed OR detected OR surveillance OR vaccination)"

    google_query = f"{diseases_q} {context_q} {countries_q}"
    gdelt_query = f'{diseases_q} {context_q} {countries_q}'

    all_items = []
    errors = []

    # 1) ProMED
    try:
        all_items.extend(fetch_promed())
    except Exception as e:
        errors.append(f"ProMED={type(e).__name__}")

    # 2) GDELT
    try:
        all_items.extend(fetch_gdelt(gdelt_query, maxrecords=60))
    except Exception as e:
        errors.append(f"GDELT={type(e).__name__}")

    # 3) Google News (fallback)
    try:
        all_items.extend(fetch_google(google_query))
    except Exception as e:
        errors.append(f"Google={type(e).__name__}")

    # Ù„Ùˆ ÙƒÙ„Ù‡Ù… ÙØ´Ù„ÙˆØ§
    if not all_items:
        tg_send(
            "âš ï¸ ØªØ¹Ø°Ø± Ø¬Ù„Ø¨ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø­Ø§Ù„ÙŠØ§Ù‹.\n"
            f"ğŸ•’ {now_ksa_str()}\n"
            f"ØªÙØ§ØµÙŠÙ„: {', '.join(errors) if errors else 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'}"
        )
        return

    new_events = []

    for it in all_items:
        # ÙÙ„ØªØ± Ø§Ù„Ø¹Ù…Ø± (Ù„Ù€ Google/GDELT â€“ ProMED Ø£Ø­ÙŠØ§Ù†Ø§Ù‹ Ø¨Ø¯ÙˆÙ† pubDate ÙˆØ§Ø¶Ø­)
        if it["source"] in ("Google News", "GDELT"):
            if not within_days(it.get("pub", ""), MAX_AGE_DAYS):
                continue

        blob = f"{it.get('title','')} {it.get('desc','')}"
        country = detect_country(blob)
        disease = detect_disease(blob)
        if not country or not disease:
            continue

        region = detect_region(blob, country)
        label = classify_item(it.get("title",""), it.get("desc",""))

        sid = make_sid(it.get("link",""), it.get("title",""))
        if sid in state["seen"]:
            continue
        state["seen"][sid] = {"first_seen": now_ksa_str(), "source": it["source"]}

        new_events.append({
            "source": it["source"],
            "country": country,
            "disease": disease,
            "region": region,
            "label": label,
            "title": it.get("title",""),
            "link": it.get("link",""),
        })

        if len(new_events) >= MAX_ITEMS:
            break

    if not new_events:
        tg_send(
            "ğŸ“„ ØªÙ‚Ø±ÙŠØ± Ø±ØµØ¯ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø­ÙŠÙˆØ§Ù†ÙŠØ© (Ù…ØµØ§Ø¯Ø± Ø¹Ø§Ù„Ù…ÙŠØ© Ù…ØªØ¹Ø¯Ø¯Ø©)\n"
            f"ğŸ•’ {now_ksa_str()}\n"
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
            "âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø´Ø§Ø±Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø·Ø§Ø¨Ù‚Ø© Ø­Ø§Ù„ÙŠØ§Ù‹.\n"
            f"â„¹ï¸ Ø­Ø§Ù„Ø© Ø§Ù„Ù…ØµØ§Ø¯Ø±: {('âœ…' if not errors else 'Ø› '.join(errors))}"
        )
        save_state(state)
        return

    lines = [
        "ğŸ“„ ØªÙ‚Ø±ÙŠØ± Ø±ØµØ¯ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø­ÙŠÙˆØ§Ù†ÙŠØ© (Ù…ØµØ§Ø¯Ø± Ø¹Ø§Ù„Ù…ÙŠØ© Ù…ØªØ¹Ø¯Ø¯Ø©)",
        f"ğŸ•’ {now_ksa_str()}",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
        f"Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: {len(new_events)}",
        f"â„¹ï¸ Ø­Ø§Ù„Ø© Ø§Ù„Ù…ØµØ§Ø¯Ø±: {('âœ…' if not errors else 'Ø› '.join(errors))}",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
    ]

    for i, e in enumerate(new_events, 1):
        lines.append(
            f"{i}) [{e['source']}] {e['label']}  ğŸ¾ {e['disease']}\n"
            f"   ğŸŒ Ø§Ù„Ø¯ÙˆÙ„Ø©: {e['country']}\n"
            f"   ğŸ“ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©: {e['region']}\n"
            f"   ğŸ“° Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {e['title']}\n"
            f"   ğŸ”— Ø§Ù„Ø±Ø§Ø¨Ø·: {e['link']}"
        )

    tg_send("\n".join(lines))
    save_state(state)


if __name__ == "__main__":
    main()
