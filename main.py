import os
import re
import json
import hashlib
import datetime
import requests
import xml.etree.ElementTree as ET

BOT = os.environ["TELEGRAM_BOT_TOKEN"]
CHAT_ID = os.environ["TELEGRAM_CHAT_ID"]

KSA_TZ = datetime.timezone(datetime.timedelta(hours=3))
STATE_FILE = "state.json"

# ===== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª =====
MAX_ITEMS = 10
MAX_AGE_DAYS = 120  # 90-180 Ù…Ù†Ø§Ø³Ø¨

COUNTRY_KEYS = {
    "saudi arabia": "Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©",
    "kingdom of saudi arabia": "Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©",
    "ksa": "Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©",
    "sudan": "Ø§Ù„Ø³ÙˆØ¯Ø§Ù†",
    "somalia": "Ø§Ù„ØµÙˆÙ…Ø§Ù„",
    "ethiopia": "Ø¥Ø«ÙŠÙˆØ¨ÙŠØ§",
    "djibouti": "Ø¬ÙŠØ¨ÙˆØªÙŠ",
    "jordan": "Ø§Ù„Ø£Ø±Ø¯Ù†",
    "india": "Ø§Ù„Ù‡Ù†Ø¯",
}

DISEASE_FULL = {
    "rift valley fever": "Ø­Ù…Ù‘Ù‰ Ø§Ù„ÙˆØ§Ø¯ÙŠ Ø§Ù„Ù…ØªØµØ¯Ù‘Ø¹ (RVF)",
    "peste des petits ruminants": "Ø·Ø§Ø¹ÙˆÙ† Ø§Ù„Ù…Ø¬ØªØ±Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© (PPR)",
    "foot and mouth disease": "Ø§Ù„Ø­Ù…Ù‘Ù‰ Ø§Ù„Ù‚Ù„Ø§Ø¹ÙŠØ© (FMD)",
    "avian influenza": "Ø¥Ù†ÙÙ„ÙˆÙ†Ø²Ø§ Ø§Ù„Ø·ÙŠÙˆØ±",
    "highly pathogenic avian influenza": "Ø¥Ù†ÙÙ„ÙˆÙ†Ø²Ø§ Ø§Ù„Ø·ÙŠÙˆØ± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¥Ù…Ø±Ø§Ø¶ (HPAI)",
    "lumpy skin disease": "Ù…Ø±Ø¶ Ø§Ù„Ø¬Ù„Ø¯ Ø§Ù„Ø¹Ù‚Ø¯ÙŠ (LSD)",
    "anthrax": "Ø§Ù„Ø¬Ù…Ø±Ø© Ø§Ù„Ø®Ø¨ÙŠØ«Ø©",
    "rabies": "Ø¯Ø§Ø¡ Ø§Ù„ÙƒÙ„Ø¨",
}

DISEASE_ABBR = {
    "rvf": "Ø­Ù…Ù‘Ù‰ Ø§Ù„ÙˆØ§Ø¯ÙŠ Ø§Ù„Ù…ØªØµØ¯Ù‘Ø¹ (RVF)",
    "ppr": "Ø·Ø§Ø¹ÙˆÙ† Ø§Ù„Ù…Ø¬ØªØ±Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© (PPR)",
    "fmd": "Ø§Ù„Ø­Ù…Ù‘Ù‰ Ø§Ù„Ù‚Ù„Ø§Ø¹ÙŠØ© (FMD)",
    "h5n1": "Ø¥Ù†ÙÙ„ÙˆÙ†Ø²Ø§ Ø§Ù„Ø·ÙŠÙˆØ± (H5N1)",
}

DISEASE_CONTEXT = [
    "outbreak", "case", "cases", "fever", "virus", "infection",
    "detected", "confirmed", "epidemic", "surveillance", "vaccination",
]

REGION_AR = {
    "riyadh": "Ø§Ù„Ø±ÙŠØ§Ø¶",
    "makkah": "Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø©",
    "madinah": "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ù†ÙˆØ±Ø©",
    "eastern province": "Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ©",
    "qassim": "Ø§Ù„Ù‚ØµÙŠÙ…",
    "asir": "Ø¹Ø³ÙŠØ±",
    "tabuk": "ØªØ¨ÙˆÙƒ",
    "hail": "Ø­Ø§Ø¦Ù„",
    "jazan": "Ø¬Ø§Ø²Ø§Ù†",
    "najran": "Ù†Ø¬Ø±Ø§Ù†",
    "khartoum": "Ø§Ù„Ø®Ø±Ø·ÙˆÙ…",
    "darfur": "Ø¯Ø§Ø±ÙÙˆØ±",
    "oromia": "Ø£ÙˆØ±ÙˆÙ…ÙŠØ§",
    "amhara": "Ø£Ù…Ù‡Ø±Ø§",
    "addis ababa": "Ø£Ø¯ÙŠØ³ Ø£Ø¨Ø§Ø¨Ø§",
    "amman": "Ø¹Ù…Ù‘Ø§Ù†",
    "irbid": "Ø¥Ø±Ø¨Ø¯",
}

# Ù…ØµØ§Ø¯Ø±
PROMED_RSS = "https://promedmail.org/promed-posts?format=rss"
GDELT_DOC = "https://api.gdeltproject.org/api/v2/doc/doc"
GOOGLE_RSS = "https://news.google.com/rss/search?q={q}&hl=en&gl=US&ceid=US:en"


# ===== ÙˆÙ‚Øª =====
def now_ksa():
    return datetime.datetime.now(tz=KSA_TZ)

def now_ksa_str():
    return now_ksa().strftime("%Y-%m-%d %H:%M") + " Ø¨ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©"


# ===== Telegram =====
def tg_send(text: str):
    url = f"https://api.telegram.org/bot{BOT}/sendMessage"
    parts = [text[i:i+3500] for i in range(0, len(text), 3500)]
    for p in parts:
        r = requests.post(
            url,
            json={"chat_id": CHAT_ID, "text": p, "disable_web_page_preview": True},
            timeout=30
        )
        r.raise_for_status()


# ===== State =====
def load_state():
    try:
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return {"seen": {}}

def save_state(state):
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

def make_sid(url, title):
    raw = (url or "") + "|" + (title or "")
    return hashlib.sha256(raw.encode()).hexdigest()[:16}


# ===== ÙƒØ´Ù =====
def detect_country(text):
    low = (text or "").lower()
    for k, v in COUNTRY_KEYS.items():
        if k in low:
            return v
    return None

def detect_region(text, country_ar):
    low = (text or "").lower()
    for k, v in REGION_AR.items():
        if k in low:
            return v
    return "Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¯ÙˆÙ„Ø©" if country_ar else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

def detect_disease(text):
    low = (text or "").lower()

    for k, v in DISEASE_FULL.items():
        if k in low:
            return v

    has_context = any(c in low for c in DISEASE_CONTEXT)
    if has_context:
        for k, v in DISEASE_ABBR.items():
            if re.search(rf"\b{k}\b", low):
                return v

    return None

def classify_item(title: str, desc: str) -> str:
    low = f"{title} {desc}".lower()
    if "outbreak" in low or "confirmed" in low or "cases" in low:
        return "ğŸŸ¥ ØªÙØ´ÙŠ/Ø­Ø§Ù„Ø§Øª"
    if "ban" in low or "imports" in low or "import ban" in low:
        return "ğŸŸ¦ Ù‚Ø±Ø§Ø±/Ù…Ù†Ø¹ Ø§Ø³ØªÙŠØ±Ø§Ø¯"
    if "study" in low or "investigation" in low or "characterization" in low:
        return "ğŸŸ© Ø¯Ø±Ø§Ø³Ø©/Ø¨Ø­Ø«"
    return "ğŸŸ¨ Ø®Ø¨Ø± Ø¹Ø§Ù…"


# ===== ÙÙ„ØªØ±Ø© Ø§Ù„Ø¹Ù…Ø± =====
def within_days(pub: str, days: int) -> bool:
    if not pub:
        return True
    try:
        # GDELT ISO: 2026-02-28T00:00:00Z
        if "T" in pub and pub.endswith("Z"):
            dt = datetime.datetime.strptime(pub, "%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=datetime.timezone.utc)
        else:
            # Google: Sat, 28 Feb 2026 00:00:00 GMT
            dt = datetime.datetime.strptime(pub, "%a, %d %b %Y %H:%M:%S %Z").replace(tzinfo=datetime.timezone.utc)
        age = now_ksa() - dt.astimezone(KSA_TZ)
        return age.days <= days
    except:
        return True


# ===== Ø¬Ù„Ø¨ ProMED (Ù‚Ø¯ ÙŠÙØ´Ù„) =====
def fetch_promed():
    headers = {"User-Agent": "Mozilla/5.0"}
    r = requests.get(PROMED_RSS, timeout=45, headers=headers)
    r.raise_for_status()
    root = ET.fromstring(r.text)

    items = []
    for it in root.findall(".//item"):
        items.append({
            "source": "ProMED",
            "title": (it.findtext("title") or "").strip(),
            "link": (it.findtext("link") or "").strip(),
            "pub": (it.findtext("pubDate") or "").strip(),
            "desc": (it.findtext("description") or "").strip(),
        })
    return items


# ===== Ø¬Ù„Ø¨ Google News (fallback Ù…Ø¶Ù…ÙˆÙ† ØºØ§Ù„Ø¨Ø§Ù‹) =====
def fetch_google(query):
    url = GOOGLE_RSS.format(q=requests.utils.quote(query))
    headers = {"User-Agent": "Mozilla/5.0"}
    r = requests.get(url, timeout=45, headers=headers)
    r.raise_for_status()
    root = ET.fromstring(r.text)

    items = []
    for it in root.findall(".//item"):
        items.append({
            "source": "Google News",
            "title": (it.findtext("title") or "").strip(),
            "link": (it.findtext("link") or "").strip(),
            "pub": (it.findtext("pubDate") or "").strip(),
            "desc": (it.findtext("description") or "").strip(),
        })
    return items


# ===== Ø¬Ù„Ø¨ GDELT (Ù…ØµÙ…Ù… Ø¶Ø¯ JSONDecodeError) =====
def fetch_gdelt(query, maxrecords=60):
    params = {
        "query": query,
        "mode": "artlist",
        "format": "json",
        "sort": "datedesc",
        "maxrecords": str(maxrecords),
    }
    headers = {"User-Agent": "Mozilla/5.0 (KSA-Animal-Health-Intel/1.0)"}
    r = requests.get(GDELT_DOC, params=params, timeout=45, headers=headers)

    # Ø¥Ø°Ø§ GDELT Ø±Ø¬Ù‘Ø¹ HTML (Ø­Ø¬Ø¨/Rate limit) Ø¨Ø¯Ø§Ù„ JSON
    ctype = (r.headers.get("content-type") or "").lower()
    text = (r.text or "").strip()

    if r.status_code != 200:
        raise requests.HTTPError(f"GDELT HTTP {r.status_code}", response=r)

    if "application/json" not in ctype and not text.startswith("{"):
        # Ù‡Ø°Ø§ Ø³Ø¨Ø¨ JSONDecodeError Ø¹Ù†Ø¯Ùƒ â€” Ù†Ø¹Ø·ÙŠ Ø®Ø·Ø£ Ù…ÙÙ‡ÙˆÙ…
        raise ValueError("GDELT returned non-JSON (likely rate-limit/block)")

    data = r.json()
    items = []
    for a in data.get("articles", []) or []:
        items.append({
            "source": "GDELT",
            "title": (a.get("title") or "").strip(),
            "link": (a.get("url") or "").strip(),
            "pub": (a.get("seendate") or "").strip(),  # ISO Z
            "desc": (a.get("snippet") or "") + " " + (a.get("sourceCountry") or ""),
        })
    return items


def main():
    state = load_state()

    countries_q = "(Saudi Arabia OR Sudan OR Somalia OR Ethiopia OR Djibouti OR Jordan OR India)"
    diseases_q = '("rift valley fever" OR RVF OR "peste des petits ruminants" OR PPR OR "foot and mouth disease" OR FMD OR "avian influenza" OR H5N1 OR "lumpy skin disease" OR anthrax OR rabies)'

    # Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø¨Ø³ÙŠØ·Ø© ØªÙ‚Ù„Ù„ â€œØµÙØ±â€
    google_query = f"{diseases_q} {countries_q}"
    gdelt_query = f"{diseases_q} {countries_q}"

    items = []
    status_notes = []

    # 1) ProMED (Ù„Ùˆ Ø§Ø´ØªØºÙ„ Ù…Ù…ØªØ§Ø²ØŒ Ù„Ùˆ ÙØ´Ù„ Ù…Ø§ ÙŠÙˆÙ‚Ù)
    try:
        items.extend(fetch_promed())
        status_notes.append("ProMED=OK")
    except Exception as e:
        status_notes.append(f"ProMED={type(e).__name__}")

    # 2) GDELT (Ù„Ùˆ Ø±Ø¬Ø¹ ØºÙŠØ± JSON Ù…Ø§ Ù†Ù†Ù‡Ø§Ø±)
    try:
        items.extend(fetch_gdelt(gdelt_query, maxrecords=80))
        status_notes.append("GDELT=OK")
    except Exception as e:
        status_notes.append(f"GDELT={type(e).__name__}")

    # 3) Google fallback
    try:
        items.extend(fetch_google(google_query))
        status_notes.append("Google=OK")
    except Exception as e:
        status_notes.append(f"Google={type(e).__name__}")

    if not items:
        tg_send(
            "âš ï¸ ØªØ¹Ø°Ø± Ø¬Ù„Ø¨ Ø£ÙŠ Ù…ØµØ¯Ø± Ø­Ø§Ù„ÙŠØ§Ù‹.\n"
            f"ğŸ•’ {now_ksa_str()}\n"
            f"Ø­Ø§Ù„Ø© Ø§Ù„Ù…ØµØ§Ø¯Ø±: {'Ø› '.join(status_notes)}"
        )
        return

    new_events = []
    for it in items:
        # ÙÙ„ØªØ±Ø© Ø¹Ù…Ø± (Ù„Ù„Ù€ Google/GDELT)
        if it["source"] in ("Google News", "GDELT"):
            if not within_days(it.get("pub", ""), MAX_AGE_DAYS):
                continue

        blob = f"{it.get('title','')} {it.get('desc','')}"
        disease = detect_disease(blob)
        country = detect_country(blob)
        if not disease or not country:
            continue

        region = detect_region(blob, country)
        label = classify_item(it.get("title",""), it.get("desc",""))

        sid = make_sid(it.get("link",""), it.get("title",""))
        if sid in state["seen"]:
            continue
        state["seen"][sid] = {"first_seen": now_ksa_str(), "source": it["source"]}

        new_events.append({
            "source": it["source"],
            "label": label,
            "disease": disease,
            "country": country,
            "region": region,
            "title": it.get("title",""),
            "link": it.get("link",""),
        })

        if len(new_events) >= MAX_ITEMS:
            break

    if not new_events:
        tg_send(
            "ğŸ“„ ØªÙ‚Ø±ÙŠØ± Ø±ØµØ¯ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø­ÙŠÙˆØ§Ù†ÙŠØ© (Ù…ØµØ§Ø¯Ø± Ù…ØªØ¹Ø¯Ø¯Ø©)\n"
            f"ğŸ•’ {now_ksa_str()}\n"
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
            "âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø´Ø§Ø±Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø·Ø§Ø¨Ù‚Ø© Ø­Ø§Ù„ÙŠØ§Ù‹.\n"
            f"â„¹ï¸ Ø­Ø§Ù„Ø© Ø§Ù„Ù…ØµØ§Ø¯Ø±: {'Ø› '.join(status_notes)}"
        )
        save_state(state)
        return

    lines = [
        "ğŸ“„ ØªÙ‚Ø±ÙŠØ± Ø±ØµØ¯ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø­ÙŠÙˆØ§Ù†ÙŠØ© (Ù…ØµØ§Ø¯Ø± Ù…ØªØ¹Ø¯Ø¯Ø©)",
        f"ğŸ•’ {now_ksa_str()}",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
        f"Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: {len(new_events)}",
        f"â„¹ï¸ Ø­Ø§Ù„Ø© Ø§Ù„Ù…ØµØ§Ø¯Ø±: {'Ø› '.join(status_notes)}",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
    ]

    for i, e in enumerate(new_events, 1):
        lines.append(
            f"{i}) [{e['source']}] {e['label']}  ğŸ¾ {e['disease']}\n"
            f"   ğŸŒ Ø§Ù„Ø¯ÙˆÙ„Ø©: {e['country']}\n"
            f"   ğŸ“ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©: {e['region']}\n"
            f"   ğŸ“° Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {e['title']}\n"
            f"   ğŸ”— Ø§Ù„Ø±Ø§Ø¨Ø·: {e['link']}"
        )

    tg_send("\n".join(lines))
    save_state(state)


if __name__ == "__main__":
    main()
