import os
import re
import json
import hashlib
import datetime
import requests
import xml.etree.ElementTree as ET

BOT = os.environ["TELEGRAM_BOT_TOKEN"]
CHAT_ID = os.environ["TELEGRAM_CHAT_ID"]

KSA_TZ = datetime.timezone(datetime.timedelta(hours=3))
STATE_FILE = "state.json"

# ===== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª =====
MAX_ITEMS = 8
MAX_AGE_DAYS = 90

COUNTRY_KEYS = {
    "saudi arabia": "Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©",
    "kingdom of saudi arabia": "Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©",
    "ksa": "Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©",
    "sudan": "Ø§Ù„Ø³ÙˆØ¯Ø§Ù†",
    "somalia": "Ø§Ù„ØµÙˆÙ…Ø§Ù„",
    "ethiopia": "Ø¥Ø«ÙŠÙˆØ¨ÙŠØ§",
    "djibouti": "Ø¬ÙŠØ¨ÙˆØªÙŠ",
    "jordan": "Ø§Ù„Ø£Ø±Ø¯Ù†",
    "india": "Ø§Ù„Ù‡Ù†Ø¯",
    "pakistan": "Ø¨Ø§ÙƒØ³ØªØ§Ù†",
    "australia": "Ø£Ø³ØªØ±Ø§Ù„ÙŠØ§",
    "brazil": "Ø§Ù„Ø¨Ø±Ø§Ø²ÙŠÙ„",
}

# Ø£Ø³Ù…Ø§Ø¡ ÙƒØ§Ù…Ù„Ø© (Ø¯Ù‚ÙŠÙ‚Ø©)
DISEASE_FULL = {
    "peste des petits ruminants": "Ø·Ø§Ø¹ÙˆÙ† Ø§Ù„Ù…Ø¬ØªØ±Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© (PPR)",
    "rift valley fever": "Ø­Ù…Ù‘Ù‰ Ø§Ù„ÙˆØ§Ø¯ÙŠ Ø§Ù„Ù…ØªØµØ¯Ù‘Ø¹ (RVF)",
    "foot and mouth disease": "Ø§Ù„Ø­Ù…Ù‘Ù‰ Ø§Ù„Ù‚Ù„Ø§Ø¹ÙŠØ© (FMD)",
    "avian influenza": "Ø¥Ù†ÙÙ„ÙˆÙ†Ø²Ø§ Ø§Ù„Ø·ÙŠÙˆØ±",
    "highly pathogenic avian influenza": "Ø¥Ù†ÙÙ„ÙˆÙ†Ø²Ø§ Ø§Ù„Ø·ÙŠÙˆØ± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¥Ù…Ø±Ø§Ø¶ (HPAI)",
    "lumpy skin disease": "Ù…Ø±Ø¶ Ø§Ù„Ø¬Ù„Ø¯ Ø§Ù„Ø¹Ù‚Ø¯ÙŠ (LSD)",
    "anthrax": "Ø§Ù„Ø¬Ù…Ø±Ø© Ø§Ù„Ø®Ø¨ÙŠØ«Ø©",
    "rabies": "Ø¯Ø§Ø¡ Ø§Ù„ÙƒÙ„Ø¨",
}

# Ø§Ø®ØªØµØ§Ø±Ø§Øª (Ù„ÙƒÙ† Ø¨Ø´Ø±Ø· Ø³ÙŠØ§Ù‚)
DISEASE_ABBR = {
    "ppr": "Ø·Ø§Ø¹ÙˆÙ† Ø§Ù„Ù…Ø¬ØªØ±Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© (PPR)",
    "rvf": "Ø­Ù…Ù‘Ù‰ Ø§Ù„ÙˆØ§Ø¯ÙŠ Ø§Ù„Ù…ØªØµØ¯Ù‘Ø¹ (RVF)",
    "fmd": "Ø§Ù„Ø­Ù…Ù‘Ù‰ Ø§Ù„Ù‚Ù„Ø§Ø¹ÙŠØ© (FMD)",
    "h5n1": "Ø¥Ù†ÙÙ„ÙˆÙ†Ø²Ø§ Ø§Ù„Ø·ÙŠÙˆØ± (H5N1)",
}

# ÙƒÙ„Ù…Ø§Øª â€œØ³ÙŠØ§Ù‚ Ù…Ø±Ø¶ÙŠâ€ Ù„Ø§Ø²Ù… ØªØ¸Ù‡Ø± Ù…Ø¹ Ø§Ù„Ø§Ø®ØªØµØ§Ø±
DISEASE_CONTEXT = [
    "outbreak", "case", "cases", "fever", "virus", "infection",
    "epidemic", "zoonotic", "detected", "confirmed", "clinical"
]

REGION_AR = {
    "riyadh": "Ø§Ù„Ø±ÙŠØ§Ø¶",
    "makkah": "Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø©",
    "madinah": "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ù†ÙˆØ±Ø©",
    "eastern province": "Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ©",
    "qassim": "Ø§Ù„Ù‚ØµÙŠÙ…",
    "asir": "Ø¹Ø³ÙŠØ±",
    "tabuk": "ØªØ¨ÙˆÙƒ",
    "hail": "Ø­Ø§Ø¦Ù„",
    "jazan": "Ø¬Ø§Ø²Ø§Ù†",
    "najran": "Ù†Ø¬Ø±Ø§Ù†",
    "khartoum": "Ø§Ù„Ø®Ø±Ø·ÙˆÙ…",
    "darfur": "Ø¯Ø§Ø±ÙÙˆØ±",
    "oromia": "Ø£ÙˆØ±ÙˆÙ…ÙŠØ§",
    "amhara": "Ø£Ù…Ù‡Ø±Ø§",
    "addis ababa": "Ø£Ø¯ÙŠØ³ Ø£Ø¨Ø§Ø¨Ø§",
    "amman": "Ø¹Ù…Ù‘Ø§Ù†",
    "irbid": "Ø¥Ø±Ø¨Ø¯",
}

GOOGLE_RSS = "https://news.google.com/rss/search?q={q}&hl=en&gl=US&ceid=US:en"


def now_ksa():
    return datetime.datetime.now(tz=KSA_TZ)

def now_ksa_str():
    return now_ksa().strftime("%Y-%m-%d %H:%M") + " Ø¨ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©"


def tg_send(text: str):
    url = f"https://api.telegram.org/bot{BOT}/sendMessage"
    parts = [text[i:i+3500] for i in range(0, len(text), 3500)]
    for p in parts:
        r = requests.post(
            url,
            json={"chat_id": CHAT_ID, "text": p, "disable_web_page_preview": True},
            timeout=30
        )
        r.raise_for_status()


def load_state():
    try:
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return {"seen": {}}

def save_state(state):
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

def make_sid(url, title):
    raw = (url or "") + "|" + (title or "")
    return hashlib.sha256(raw.encode()).hexdigest()[:16]


def detect_country(text):
    low = (text or "").lower()
    for k, v in COUNTRY_KEYS.items():
        if k in low:
            return v
    return None

def detect_region(text, country_ar):
    low = (text or "").lower()
    for k, v in REGION_AR.items():
        if k in low:
            return v
    # Ø¨Ø¯Ù„ "ØºÙŠØ± Ù…Ø­Ø¯Ø¯" Ù†Ø®Ù„ÙŠÙ‡Ø§ Ù…ÙÙ‡ÙˆÙ…Ø©
    return "Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¯ÙˆÙ„Ø©" if country_ar else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

def detect_disease_balanced(text):
    low = (text or "").lower()

    # 1) Ø£Ø³Ù…Ø§Ø¡ ÙƒØ§Ù…Ù„Ø©
    for k, v in DISEASE_FULL.items():
        if k in low:
            return v

    # 2) Ø§Ø®ØªØµØ§Ø±Ø§Øª Ø¨Ø´Ø±Ø· Ø³ÙŠØ§Ù‚
    has_context = any(c in low for c in DISEASE_CONTEXT)
    if has_context:
        for k, v in DISEASE_ABBR.items():
            # ÙƒÙ„Ù…Ø© ÙƒØ§Ù…Ù„Ø© ÙƒØ§Ø®ØªØµØ§Ø± (Ø­Ø¯ÙˆØ¯)
            if re.search(rf"\b{k}\b", low):
                return v

    return None

def classify_item(title: str, desc: str) -> str:
    low = f"{title} {desc}".lower()
    if "outbreak" in low or "confirmed" in low or "cases" in low:
        return "ğŸŸ¥ ØªÙØ´ÙŠ/Ø­Ø§Ù„Ø§Øª"
    if "ban" in low or "imports" in low or "import ban" in low:
        return "ğŸŸ¦ Ù‚Ø±Ø§Ø±/Ù…Ù†Ø¹ Ø§Ø³ØªÙŠØ±Ø§Ø¯"
    if "study" in low or "investigation" in low or "characterization" in low:
        return "ğŸŸ© Ø¯Ø±Ø§Ø³Ø©/Ø¨Ø­Ø«"
    return "ğŸŸ¨ Ø®Ø¨Ø± Ø¹Ø§Ù…"

def is_recent(pubdate):
    try:
        dt = datetime.datetime.strptime(pubdate, "%a, %d %b %Y %H:%M:%S %Z")
        dt = dt.replace(tzinfo=datetime.timezone.utc)
        age = now_ksa() - dt.astimezone(KSA_TZ)
        return age.days <= MAX_AGE_DAYS
    except:
        return True

def fetch_google_rss(query):
    url = GOOGLE_RSS.format(q=requests.utils.quote(query))
    headers = {"User-Agent": "Mozilla/5.0"}
    r = requests.get(url, timeout=45, headers=headers)
    r.raise_for_status()
    root = ET.fromstring(r.text)

    items = []
    for it in root.findall(".//item"):
        items.append({
            "title": (it.findtext("title") or "").strip(),
            "link": (it.findtext("link") or "").strip(),
            "pub": (it.findtext("pubDate") or "").strip(),
            "desc": (it.findtext("description") or "").strip(),
        })
    return items


def main():
    state = load_state()

    # âœ… Ø¨Ø­Ø« Ø£ÙˆØ³Ø¹ Ø´ÙˆÙŠ Ù„ÙƒÙ† Ù…Ø±ØªØ¨Ø· Ø¨Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø­ÙŠÙˆØ§Ù†ÙŠØ©
    queries = [
        '("rift valley fever" OR RVF OR "peste des petits ruminants" OR PPR OR "foot and mouth disease" OR FMD OR "avian influenza" OR H5N1 OR "lumpy skin disease") (outbreak OR cases OR virus OR fever OR detected OR confirmed) (Saudi Arabia OR Sudan OR Somalia OR Ethiopia OR Djibouti OR Jordan OR India)'
    ]

    all_items = []
    try:
        for q in queries:
            all_items.extend(fetch_google_rss(q))
    except Exception as e:
        tg_send(f"âš ï¸ ØªØ¹Ø°Ø± Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø­Ø§Ù„ÙŠØ§Ù‹.\nğŸ•’ {now_ksa_str()}\nØ§Ù„Ø³Ø¨Ø¨: {type(e).__name__}")
        return

    new_events = []

    for it in all_items:
        if not is_recent(it["pub"]):
            continue

        blob = f"{it['title']} {it['desc']}"

        disease = detect_disease_balanced(blob)
        if not disease:
            continue

        country = detect_country(blob)
        if not country:
            continue

        region = detect_region(blob, country)
        label = classify_item(it["title"], it["desc"])

        sid = make_sid(it["link"], it["title"])
        if sid in state["seen"]:
            continue
        state["seen"][sid] = {"first_seen": now_ksa_str()}

        new_events.append({
            "country": country,
            "disease": disease,
            "region": region,
            "label": label,
            "title": it["title"],
            "link": it["link"]
        })

        if len(new_events) >= MAX_ITEMS:
            break

    if not new_events:
        tg_send(
            "ğŸ“„ ØªÙ‚Ø±ÙŠØ± Ø±ØµØ¯ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø­ÙŠÙˆØ§Ù†ÙŠØ© (Google News)\n"
            f"ğŸ•’ {now_ksa_str()}\n"
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
            "âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø®Ø¨Ø§Ø± Ø¬Ø¯ÙŠØ¯Ø© Ø­Ø¯ÙŠØ«Ø© Ù…Ø·Ø§Ø¨Ù‚Ø©.\n"
            "ğŸŸ¢ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ÙŠØ©: Ù…Ø³ØªÙ‚Ø±"
        )
        save_state(state)
        return

    lines = [
        "ğŸ“„ ØªÙ‚Ø±ÙŠØ± Ø±ØµØ¯ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø­ÙŠÙˆØ§Ù†ÙŠØ© (Google News)",
        f"ğŸ•’ {now_ksa_str()}",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
        f"Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: {len(new_events)}",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
    ]

    for i, e in enumerate(new_events, 1):
        lines.append(
            f"{i}) {e['label']}  ğŸ¾ {e['disease']}\n"
            f"   ğŸŒ Ø§Ù„Ø¯ÙˆÙ„Ø©: {e['country']}\n"
            f"   ğŸ“ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©: {e['region']}\n"
            f"   ğŸ“° Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {e['title']}\n"
            f"   ğŸ”— Ø§Ù„Ø±Ø§Ø¨Ø·: {e['link']}"
        )

    tg_send("\n".join(lines))
    save_state(state)

if __name__ == "__main__":
    main()
